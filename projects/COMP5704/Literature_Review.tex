
% ===========================================================================
% Title:
% ---------------------------------------------------------------------------
% to create Type I fonts type "dvips -P cmz -t letter <filename>"
% ===========================================================================
\documentclass[11pt]{article}       %--- LATEX 2e base
\usepackage{latexsym}               %--- LATEX 2e base
%---------------- Wide format -----------------------------------------------
\textwidth=6in \textheight=9in \oddsidemargin=0.25in
\evensidemargin=0.25in \topmargin=-0.5in
%--------------- Def., Theorem, Proof, etc. ---------------------------------
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{property}{Property}
\newtheorem{observation}{Observation}
\newtheorem{fact}{Fact}
\newenvironment{proof}           {\noindent{\bf Proof.} }%
                                 {\null\hfill$\Box$\par\medskip}
%--------------- Algorithm --------------------------------------------------
\newtheorem{algX}{Algorithm}
\newenvironment{algorithm}       {\begin{algX}\begin{em}}%
                                 {\par\noindent --- End of Algorithm ---
                                 \end{em}\end{algX}}
\newcommand{\step}[2]            {\begin{list}{}
                                  {  \setlength{\topsep}{0cm}
                                     \setlength{\partopsep}{0cm}
                                     \setlength{\leftmargin}{0.8cm}
                                     \setlength{\labelwidth}{0.7cm}
                                     \setlength{\labelsep}{0.1cm}    }
                                  \item[#1]#2    \end{list}}
                                 % usage: \begin{algorithm} \label{xyz}
                                 %        ... \step{(1)}{...} ...
                                 %        \end{algorithm}
%--------------- Figures ----------------------------------------------------
\usepackage{graphicx}

\newcommand{\includeFig}[3]      {\begin{figure}[htb] \begin{center}
                                 \includegraphics
                                 [width=4in,keepaspectratio] %comment this line to disable scaling
                                 {#2}\caption{\label{#1}#3} \end{center} \end{figure}}
                                 % usage: \includeFig{label}{file}{caption}


% ===========================================================================
\begin{document}
% ===========================================================================

% ############################################################################
% Title
% ############################################################################

\title{LITERATURE REVIEW: --- Parallelizing the Interpolation between Latent Space of Autoencoder Networks to Introduce Novelty in 3D Object Reconstruction}


% ############################################################################
% Author(s) (no blank lines !)
\author{
% ############################################################################
Tansin Jahan\\
School of Computer Science\\
Carleton University\\
Ottawa, Canada K1S 5B6\\
{\em tansinjahan@cmail.carleton.ca}
% ############################################################################
} % end-authors
% ############################################################################
\date{October 5,2018}
\maketitle



% ############################################################################
\section{Introduction} \label{intro}
% ############################################################################

The idea of parallel computing infers to execute more than one tasks simultaneously so that the complexity(ex- time, space etc.) in computation can be carried out smoothly. Though this is the simplest definition of parallel computing, in the real world, parallelization means a lot more than just handling the complexity in the computation of algorithms. With the development of Deep Learning Networks, parallel computing has become the essential choice for the implementation of these huge networks.Typically there are million of parameters(weights, biases) and a large amount of data involves in a CNN model. This large amount of data produces as output at each layer is known as Forwarding propagation. The loss is calculated at the same time and updated parameters are backpropagated to the layers to minimize the loss. For this, the different optimization technique is applied such as Stochastic Gradient Descent or ADAM etc. This whole process is computationally expensive and therefore needs to be parallelized so that the training time minimizes and the network can run faster than usual times. 

So, this project involves building a simple Autoencoder neural network which is popular to reconstruct 2D or 3D object given as an input. Autoencoder, being a symmetrical deep network involves several convolutional layer and parameters mentioned above. Typically this network feeds on 2D images involving higher dimension and then reduces that into lower dimension \cite{dr8} which is called as latent space. In latent space (represents as Z vector) the input object has minimum dimension with maximum features. From the lower dimension, the Z vector passes through deconvolution and therefore produces the same 2D images.   

% ############################################################################
\section{Literature Review} \label{litrev}
% ############################################################################

With the recent development of Convolutional Neural Network, it has been used to solve several Computer Vision problem. For example, object detection or reconstruction from input image, semantic information extraction from a scenario, object segmentation- these are all recent computer vision application where CNN has been used to produce better result. Likewise, 3D reconstruction of an object is one of the Computer Vision problem and recently multiple approaches (ex: 3D-GAN, 3D-shapenets) has been proposed as a solution to the problem \cite{dr1}. Previous work shows that given a depth image as input, the volumetric representation can be produced \cite{dr2}. Following these works, an approach to reconstruct 3D voxelized object from different viewpoint of one or more images of that object (i.e. single-view or multi-view) is proposed where recurrent neural network has been used \cite{dr7}. In total 50,000 model is used to train and test the proposed network. Training the network with this large amount of data is really time consuming and therefore introducing parallelism between the layers of the model can help to improve the performance of the network.

\subsection{GPU implementation} \label{GPUimpl}
GPU implementation for convolutional operation of deep networks has become very popular to improve state-of-the-art results. In the paper, 'Imagenet classification with deep convolutional neural networks' - two GTX 580 3GB GPU has been used to train the network which took five to six days to complete the whole training \cite{dr5}. In this parallelization scheme, they kept half of the kernels (or neurons) on each GPU, where the GPUs communicate only in certain layers.

Though a single GPU can greatly accelerate neural network training and testing, sometimes it is desirable
for muptiple GPUs to be used at once because the neural network model and data may not fit onto a single GPU or training with one GPU will simply take too long. Many researchers have approached the question of how to best use multiple GPUs to train deep networks more effectively. So, here I discuss one such method to parallelize convolutional neural networks described by Krizhevsky in his article ‘One weird trick for parallelizing convolutional neural networks’ \cite{dr4}. Many convolutional neural networks comprise both convolutional layers, where the linear function f(x) is a convolution of the input and a set of
learned weights, and fully connected layers, where the linear function f(x) is an inner product between the input and a set of learned weights. Krizhevsky’s key insight is that different types of parallelization are better for different types of layers. Convolutional layers generally require a large amount of computation, but have fewer parameters than fully connected layers. Thus, sharing updated parameters between GPUs is less burdensome than for fully connected layers, and splitting data amongst multiple GPUs helps speed computation. To this end, Krizevsky proposed parallelizing the convolutions with ‘data parallelization’, where the same convolutional layers are on each GPU, but the GPU process different batches of the data, and parallelizing the fully connected layers with ‘model parallelism’, where the model is split amongst GPUs, but each GPU sees the same data \cite{dr4}.


% ############################################################################
% Bibliography
% ############################################################################
\bibliographystyle{plain}
\bibliography{my-bibliography}     %loads my-bibliography.bib

% ============================================================================
\end{document}
% ============================================================================
